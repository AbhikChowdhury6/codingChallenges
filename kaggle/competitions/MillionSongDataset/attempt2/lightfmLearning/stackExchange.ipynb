{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lightfm.datasets import fetch_stackexchange\n",
    "\n",
    "data = fetch_stackexchange('crossvalidated',\n",
    "                           test_set_fraction=0.1,\n",
    "                           indicator_features=False,\n",
    "                           tag_features=True)\n",
    "\n",
    "train = data['train']\n",
    "test = data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 3213 users and 72360 items, with 4453 interactions in the test and 57795 interactions in the training set.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset has %s users and %s items, '\n",
    "      'with %s interactions in the test and %s interactions in the training set.'\n",
    "      % (train.shape[0], train.shape[1], test.getnnz(), train.getnnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 330 ms, sys: 4.44 ms, total: 335 ms\n",
      "Wall time: 190 ms\n"
     ]
    }
   ],
   "source": [
    "# Import the model\n",
    "from lightfm import LightFM\n",
    "\n",
    "# Set the number of threads; you can increase this\n",
    "# ify you have more physical cores available.\n",
    "NUM_THREADS = 2\n",
    "NUM_COMPONENTS = 30\n",
    "NUM_EPOCHS = 3\n",
    "ITEM_ALPHA = 1e-6\n",
    "\n",
    "# Let's fit a WARP model: these generally have the best performance.\n",
    "model = LightFM(loss='warp',\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "               no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Run 3 epochs and time it.\n",
    "%time model = model.fit(train, epochs=NUM_EPOCHS, num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering train AUC: 0.891659\n"
     ]
    }
   ],
   "source": [
    "# Import the evaluation routines\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model, train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering test AUC: 0.41157046\n"
     ]
    }
   ],
   "source": [
    "# We pass in the train interactions to exclude them from predictions.\n",
    "# This is to simulate a recommender system where we do not\n",
    "# re-recommend things the user has already interacted with in the train\n",
    "# set.\n",
    "test_auc = auc_score(model, test, train_interactions=train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collaborative filtering test AUC: 0.54261106\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set biases to zero\n",
    "model.item_biases *= 0.0\n",
    "\n",
    "test_auc = auc_score(model, test, train_interactions=train, num_threads=NUM_THREADS).mean()\n",
    "print('Collaborative filtering test AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1246 distinct tags, with values like ['bayesian', 'prior', 'elicitation'].\n"
     ]
    }
   ],
   "source": [
    "item_features = data['item_features']\n",
    "tag_labels = data['item_feature_labels']\n",
    "\n",
    "print('There are %s distinct tags, with values like %s.' % (item_features.shape[1], tag_labels[:3].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model instance\n",
    "model = LightFM(loss='warp',\n",
    "                item_alpha=ITEM_ALPHA,\n",
    "                no_components=NUM_COMPONENTS)\n",
    "\n",
    "# Fit the hybrid model. Note that this time, we pass\n",
    "# in the item features matrix.\n",
    "model = model.fit(train,\n",
    "                item_features=item_features,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                num_threads=NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid training set AUC: 0.8537007\n"
     ]
    }
   ],
   "source": [
    "# Don't forget the pass in the item features again!\n",
    "train_auc = auc_score(model,\n",
    "                      train,\n",
    "                      item_features=item_features,\n",
    "                      num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid training set AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid test set AUC: 0.7285901\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_auc = auc_score(model,\n",
    "                    test,\n",
    "                    train_interactions=train,\n",
    "                    item_features=item_features,\n",
    "                    num_threads=NUM_THREADS).mean()\n",
    "print('Hybrid test set AUC: %s' % test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar tags for bayesian: ['mcmc' 'posterior' 'r-project']\n",
      "Most similar tags for regression: ['log-likelihood' 'bic' 'rare-events']\n",
      "Most similar tags for survival: ['cox-model' 'incidence-rate-ratio' 'epidemiology']\n"
     ]
    }
   ],
   "source": [
    "def get_similar_tags(model, tag_id):\n",
    "    # Define similarity as the cosine of the angle\n",
    "    # between the tag latent vectors\n",
    "    \n",
    "    # Normalize the vectors to unit length\n",
    "    tag_embeddings = (model.item_embeddings.T\n",
    "                      / np.linalg.norm(model.item_embeddings, axis=1)).T\n",
    "    \n",
    "    query_embedding = tag_embeddings[tag_id]\n",
    "    similarity = np.dot(tag_embeddings, query_embedding)\n",
    "    most_similar = np.argsort(-similarity)[1:4]\n",
    "    \n",
    "    return most_similar\n",
    "\n",
    "\n",
    "for tag in (u'bayesian', u'regression', u'survival'):\n",
    "    tag_id = tag_labels.tolist().index(tag)\n",
    "    print('Most similar tags for %s: %s' % (tag_labels[tag_id],\n",
    "                                            tag_labels[get_similar_tags(model, tag_id)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
