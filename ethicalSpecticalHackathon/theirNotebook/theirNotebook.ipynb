{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN_LEN = 128 #@param\n",
    "EPOCHS = 20 #@param\n",
    "BATCH_SIZE = 16 #@param\n",
    "PATIENCE = 3 #@param\n",
    "BERT_MODEL_NAME = 'bert-base-uncased' #@param\n",
    "BASE_LEARNING_RATE = 5e-5 #@param\n",
    "WARMUP_EPOCHS = 7 #@param\n",
    "NUM_TOP_BERT_LAYERS_FREEZE = 0 #@param\n",
    "DROPOUT_PROB = 0.00 #@param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chowder/anaconda3/envs/eshack/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch_lightning is already installed.\n",
      "transformers is already installed.\n",
      "torchmetrics is already installed.\n",
      "datasets is already installed.\n",
      "plotly is already installed.\n",
      "All packages are installed.\n"
     ]
    }
   ],
   "source": [
    "# these could just be pip installs but this way you can run all the cells faster\n",
    "\n",
    "#@title Install dependencies\n",
    "\n",
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "# Define the packages and their versions\n",
    "packages = {\n",
    "  'pytorch_lightning': '==2.4.0',\n",
    "  'transformers': '==4.42.4',\n",
    "  'torchmetrics': '==1.4.1',\n",
    "  'datasets': '==2.20.0',\n",
    "  'plotly': \"\"\n",
    "}\n",
    "\n",
    "def install_package(package_name, version=None):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"{package_name} is already installed.\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package_name}...\")\n",
    "        if version:\n",
    "            subprocess.check_call(['pip', 'install', f'{package_name}{version}', '--quiet'])\n",
    "        else:\n",
    "            subprocess.check_call(['pip', 'install', package_name, '--quiet'])\n",
    "\n",
    "for package, version in packages.items():\n",
    "    install_package(package, version)\n",
    "\n",
    "print(\"All packages are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics.classification import Accuracy, F1Score, AUROC\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>outlet</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "      <th>news_link</th>\n",
       "      <th>biased_words</th>\n",
       "      <th>uuid</th>\n",
       "      <th>type</th>\n",
       "      <th>label_opinion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NYPD Commissioner Dermot Shea on Monday expres...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>0</td>\n",
       "      <td>marriage-equality</td>\n",
       "      <td>http://feedproxy.google.com/~r/breitbart/~3/F5...</td>\n",
       "      <td>[]</td>\n",
       "      <td>GtvFWZmmQmybyeMnb8Wbsr</td>\n",
       "      <td>None</td>\n",
       "      <td>Entirely factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>School systems across the country are adopting...</td>\n",
       "      <td>Federalist</td>\n",
       "      <td>1</td>\n",
       "      <td>islam</td>\n",
       "      <td>https://thefederalist.com/2020/07/08/black-liv...</td>\n",
       "      <td>['indoctrinating', 'Marxist', 'alarming']</td>\n",
       "      <td>mvoQPtabs6NZbby6LkLbms</td>\n",
       "      <td>None</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And then along came President Barry Obama, who...</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>1</td>\n",
       "      <td>marriage-equality</td>\n",
       "      <td>http://feedproxy.google.com/~r/breitbart/~3/ks...</td>\n",
       "      <td>['what', 'the', 'hell']</td>\n",
       "      <td>RDWPbijx3n2aw6NiMHt7di</td>\n",
       "      <td>None</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The curfews, which have never before occurred ...</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>1</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>https://www.alternet.org/2020/06/we-just-got-a...</td>\n",
       "      <td>['false', 'claims']</td>\n",
       "      <td>2uYKw5KpXasJWH65WCjSu4</td>\n",
       "      <td>left</td>\n",
       "      <td>Entirely factual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rather than help be a part of the solution, Tr...</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>1</td>\n",
       "      <td>elections-2020</td>\n",
       "      <td>https://www.alternet.org/2020/06/trump-thought...</td>\n",
       "      <td>['racist']</td>\n",
       "      <td>SRGvrzY9PkvtHESdts35Rw</td>\n",
       "      <td>left</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      outlet  label  \\\n",
       "0  NYPD Commissioner Dermot Shea on Monday expres...   Breitbart      0   \n",
       "1  School systems across the country are adopting...  Federalist      1   \n",
       "2  And then along came President Barry Obama, who...   Breitbart      1   \n",
       "3  The curfews, which have never before occurred ...    Alternet      1   \n",
       "4  Rather than help be a part of the solution, Tr...    Alternet      1   \n",
       "\n",
       "               topic                                          news_link  \\\n",
       "0  marriage-equality  http://feedproxy.google.com/~r/breitbart/~3/F5...   \n",
       "1              islam  https://thefederalist.com/2020/07/08/black-liv...   \n",
       "2  marriage-equality  http://feedproxy.google.com/~r/breitbart/~3/ks...   \n",
       "3     elections-2020  https://www.alternet.org/2020/06/we-just-got-a...   \n",
       "4     elections-2020  https://www.alternet.org/2020/06/trump-thought...   \n",
       "\n",
       "                                biased_words                    uuid  type  \\\n",
       "0                                         []  GtvFWZmmQmybyeMnb8Wbsr  None   \n",
       "1  ['indoctrinating', 'Marxist', 'alarming']  mvoQPtabs6NZbby6LkLbms  None   \n",
       "2                    ['what', 'the', 'hell']  RDWPbijx3n2aw6NiMHt7di  None   \n",
       "3                        ['false', 'claims']  2uYKw5KpXasJWH65WCjSu4  left   \n",
       "4                                 ['racist']  SRGvrzY9PkvtHESdts35Rw  left   \n",
       "\n",
       "                label_opinion  \n",
       "0            Entirely factual  \n",
       "1  Expresses writer’s opinion  \n",
       "2  Expresses writer’s opinion  \n",
       "3            Entirely factual  \n",
       "4  Expresses writer’s opinion  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Load BABE Training Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mediabiasgroup/BABE\", split=\"train\")\n",
    "dataset = pd.DataFrame(dataset)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_df: (2964, 9)\n",
      "Shape of val_df: (157, 9)\n"
     ]
    }
   ],
   "source": [
    "#@title Split into Training and Validation Sets\n",
    "\n",
    "train_df, val_df = train_test_split(dataset, test_size=0.05, random_state=42)\n",
    "\n",
    "print(f\"Shape of train_df: {train_df.shape}\")\n",
    "print(f\"Shape of val_df: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "\n",
    "class SocialBiasDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: BertTokenizer, max_token_len: int = 128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "        text_str = data_row['text']\n",
    "        label = data_row['label']\n",
    "\n",
    "        # tokenize the text\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text_str,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            text_str=text_str,\n",
    "            input_ids=encoding[\"input_ids\"].flatten(), # flatten to single dimension\n",
    "            attention_mask=encoding[\"attention_mask\"].flatten(), # flatten to single dimension\n",
    "            label=torch.FloatTensor([label]) # turns the int into a tensor w it as the only valuse, still one dimension\n",
    "\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text_str', 'input_ids', 'attention_mask', 'label']) \n",
      "\n",
      "text_str: This wasn’t a moment of anger where Keon called someone a racist or sexist name because he’d lost his temper or felt threatened.\n",
      "input_ids shape: torch.Size([128])\n",
      "attention_mask shape: torch.Size([128])\n",
      "labels shape: torch.Size([1]) -- ex. tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "train_dataset = SocialBiasDataset(\n",
    "  train_df,\n",
    "  tokenizer,\n",
    "  max_token_len=MAX_TOKEN_LEN\n",
    ")\n",
    "\n",
    "sample_item = train_dataset[0]\n",
    "print(sample_item.keys(), \"\\n\")\n",
    "print(f\"text_str: {sample_item['text_str']}\")\n",
    "print(f\"input_ids shape: {sample_item['input_ids'].shape}\")\n",
    "print(f\"attention_mask shape: {sample_item['attention_mask'].shape}\")\n",
    "print(f\"labels shape: {sample_item['label'].shape} -- ex. {sample_item['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SocialBiasDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_df, test_df, tokenizer, batch_size=16, max_token_len=128):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # use the pt datasets defined above\n",
    "        self.train_dataset = SocialBiasDataset(self.train_df, self.tokenizer, self.max_token_len)\n",
    "        self.test_dataset = SocialBiasDataset(self.test_df, self.tokenizer, self.max_token_len)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=4\n",
    "        )\n",
    "\n",
    "# init the data module\n",
    "data_module = SocialBiasDataModule(\n",
    "    train_df,\n",
    "    val_df,\n",
    "    tokenizer,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_token_len=MAX_TOKEN_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SocialBiasClassifier(pl.LightningModule):\n",
    "    def __init__(self, n_training_steps=None, n_warmup_steps=None, num_layers_to_freeze=0, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(self.bert.config.hidden_size, 1)  # 1 neuron for binary classification\n",
    "        )\n",
    "        self.n_training_steps = n_training_steps\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.loss_fn = nn.BCELoss()  # using binary cross entropy loss\n",
    "\n",
    "        # freeze layers (wasn't useful in testing)\n",
    "        self.freeze_bert_layers(num_layers_to_freeze)\n",
    "\n",
    "        # metrics\n",
    "        self.train_accuracy = Accuracy(task=\"binary\")\n",
    "        self.val_accuracy = Accuracy(task=\"binary\")\n",
    "        self.train_f1 = F1Score(task=\"binary\")\n",
    "        self.val_f1 = F1Score(task=\"binary\")\n",
    "        self.train_outputs = [] # used in train_auroc\n",
    "        self.train_auroc = AUROC(task=\"binary\")\n",
    "        self.val_auroc = AUROC(task=\"binary\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        # # mean pooling\n",
    "        # attention_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size())\n",
    "        # sum_hidden_states = torch.sum(hidden_states * attention_mask_expanded, dim=1)\n",
    "        # num_tokens = torch.sum(attention_mask, dim=1).clamp(min=1)  # don't divide by 0\n",
    "        # mean_pooled_output = sum_hidden_states / num_tokens.unsqueeze(-1)  # reshape num_tokens?\n",
    "\n",
    "        pooler_output = output.pooler_output\n",
    "        output = self.classifier(output.pooler_output) # change this to mean_pooled_output if you uncomment the lines above\n",
    "        output = torch.sigmoid(output).squeeze(-1)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(output, labels)\n",
    "\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # parse batch\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"label\"].squeeze(-1)  # squeeze labels to match outputs shape\n",
    "\n",
    "        # run forward pass\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "\n",
    "        # metrics\n",
    "        self.train_accuracy(outputs, labels.int())\n",
    "        self.train_f1(outputs, labels.int())\n",
    "        self.train_auroc(outputs, labels.int())\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_accuracy\", self.train_accuracy, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_f1\", self.train_f1, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_auroc\", self.train_auroc, on_step=True, on_epoch=True)\n",
    "        self.log(\"batch_size\", input_ids.size(0), prog_bar=True, logger=True)\n",
    "        self.train_outputs.append({\"predictions\": outputs, \"labels\": labels})\n",
    "\n",
    "        return {\"loss\": loss, \"predictions\": outputs, \"labels\": labels}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"label\"].squeeze(-1)\n",
    "        loss, outputs = self(input_ids, attention_mask, labels)\n",
    "        self.val_accuracy(outputs, labels.int())\n",
    "        self.val_f1(outputs, labels.int())\n",
    "        self.val_auroc(outputs, labels.int())\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_accuracy\", self.val_accuracy, on_step=True, on_epoch=True)\n",
    "        self.log(\"val_f1\", self.val_f1, on_step=True, on_epoch=True)\n",
    "        self.log(\"val_auroc\", self.val_auroc, on_step=True, on_epoch=True)\n",
    "        self.log(\"batch_size\", input_ids.size(0), prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=BASE_LEARNING_RATE)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.n_warmup_steps,\n",
    "            num_training_steps=self.n_training_steps\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        labels = torch.cat([output[\"labels\"] for output in self.train_outputs])\n",
    "        predictions = torch.cat([output[\"predictions\"] for output in self.train_outputs])\n",
    "        class_roc_auc = self.train_auroc(predictions, labels.int())\n",
    "        self.log('train_roc_auc', class_roc_auc, prog_bar=True, logger=True)\n",
    "        self.train_outputs = []  # clear outputs for the next epoch\n",
    "\n",
    "    # currently freezing top layers but we could try bottom\n",
    "    def freeze_bert_layers(self, num_layers_to_freeze):\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Set requires_grad to False for the specified number of layers\n",
    "        for i, layer in enumerate(self.bert.encoder.layer):\n",
    "            if i < num_layers_to_freeze:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup Steps: 1295\n",
      "Total Training Steps: 3700\n",
      "Model initialized\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = len(train_df) // BATCH_SIZE\n",
    "total_training_steps = steps_per_epoch * EPOCHS\n",
    "warmup_percentage = WARMUP_EPOCHS / EPOCHS\n",
    "warmup_steps = int(total_training_steps * warmup_percentage)\n",
    "print(\"Warmup Steps:\", warmup_steps)\n",
    "print(\"Total Training Steps:\", total_training_steps)\n",
    "\n",
    "model = SocialBiasClassifier(\n",
    "    n_warmup_steps=warmup_steps,\n",
    "    n_training_steps=total_training_steps,\n",
    "    num_layers_to_freeze=NUM_TOP_BERT_LAYERS_FREEZE,\n",
    "    dropout_prob=DROPOUT_PROB\n",
    ")\n",
    "print(\"Model initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Callbacks for selecting the best checkpoint\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='social-bias-model/',\n",
    "    filename='best-checkpoint',\n",
    "    save_top_k=1,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=PATIENCE,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Logging for viewing in TensorBoard\n",
    "logger = TensorBoardLogger('lightning_logs', name='social-bias-model')\n",
    "\n",
    "# PL trainer with profiler\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    max_epochs=EPOCHS,\n",
    "    log_every_n_steps=1,\n",
    "    profiler=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf lightning_logs/\n",
    "!rm -rf checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs/social-bias-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/chowder/anaconda3/envs/eshack/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/chowder/Documents/AiLearning/codingChallenges/ethicalSpecticalHackathon/theirNotebook/social-bias-model exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/chowder/anaconda3/envs/eshack/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name           | Type           | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | bert           | BertModel      | 109 M  | eval \n",
      "1 | classifier     | Sequential     | 769    | train\n",
      "2 | loss_fn        | BCELoss        | 0      | train\n",
      "3 | train_accuracy | BinaryAccuracy | 0      | train\n",
      "4 | val_accuracy   | BinaryAccuracy | 0      | train\n",
      "5 | train_f1       | BinaryF1Score  | 0      | train\n",
      "6 | val_f1         | BinaryF1Score  | 0      | train\n",
      "7 | train_auroc    | BinaryAUROC    | 0      | train\n",
      "8 | val_auroc      | BinaryAUROC    | 0      | train\n",
      "----------------------------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.932   Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "228       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 186/186 [00:41<00:00,  4.47it/s, v_num=0, train_loss=0.278, batch_size=4.000, val_loss=0.442, train_roc_auc=0.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chowder/anaconda3/envs/eshack/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 186/186 [00:42<00:00,  4.43it/s, v_num=0, train_loss=0.111, batch_size=15.80, val_loss=0.497, train_roc_auc=0.993]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                               \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                \t|  -              \t|  41078          \t|  219.48         \t|  100 %          \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                   \t|  41.906         \t|  5              \t|  209.53         \t|  95.466         \t|\n",
      "|  run_training_batch                                                                                                                                                   \t|  0.19944        \t|  930            \t|  185.48         \t|  84.51          \t|\n",
      "|  [LightningModule]SocialBiasClassifier.optimizer_step                                                                                                                 \t|  0.19937        \t|  930            \t|  185.42         \t|  84.48          \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                         \t|  0.066559       \t|  930            \t|  61.9           \t|  28.203         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                         \t|  0.016879       \t|  930            \t|  15.698         \t|  7.1522         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                              \t|  0.01411        \t|  930            \t|  13.122         \t|  5.9788         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  1.3865         \t|  5              \t|  6.9324         \t|  3.1586         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                       \t|  0.069172       \t|  52             \t|  3.5969         \t|  1.6389         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                           \t|  0.0012746      \t|  930            \t|  1.1853         \t|  0.54007        \t|\n",
      "|  [LightningModule]SocialBiasClassifier.optimizer_zero_grad                                                                                                            \t|  0.00045382     \t|  930            \t|  0.42206        \t|  0.1923         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                       \t|  0.0002607      \t|  982            \t|  0.256          \t|  0.11664        \t|\n",
      "|  [LightningModule]SocialBiasClassifier.transfer_batch_to_device                                                                                                       \t|  0.00021782     \t|  982            \t|  0.2139         \t|  0.097459       \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                           \t|  0.0022863      \t|  52             \t|  0.11889        \t|  0.054167       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                    \t|  0.0015212      \t|  52             \t|  0.079104       \t|  0.036042       \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_train_epoch_end                                                                                                             \t|  0.013697       \t|  5              \t|  0.068485       \t|  0.031203       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                       \t|  0.0080184      \t|  5              \t|  0.040092       \t|  0.018267       \t|\n",
      "|  [LightningModule]SocialBiasClassifier.configure_gradient_clipping                                                                                                    \t|  2.5395e-05     \t|  930            \t|  0.023618       \t|  0.010761       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  2.3137e-05     \t|  930            \t|  0.021518       \t|  0.0098039      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.lr_scheduler_step                                                                                                              \t|  1.9621e-05     \t|  930            \t|  0.018248       \t|  0.008314       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                        \t|  0.0030099      \t|  6              \t|  0.01806        \t|  0.0082284      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                  \t|  0.00032744     \t|  52             \t|  0.017027       \t|  0.0077577      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                               \t|  0.015571       \t|  1              \t|  0.015571       \t|  0.0070946      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                          \t|  0.002211       \t|  6              \t|  0.013266       \t|  0.0060443      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                         \t|  0.0025682      \t|  5              \t|  0.012841       \t|  0.0058506      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_model_eval                                                                                                       \t|  0.0013697      \t|  6              \t|  0.0082183      \t|  0.0037445      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_model_zero_grad                                                                                                  \t|  0.0012403      \t|  5              \t|  0.0062015      \t|  0.0028256      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_end                                                                                     \t|  0.0011256      \t|  5              \t|  0.0056279      \t|  0.0025642      \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                            \t|  5.3498e-06     \t|  930            \t|  0.0049753      \t|  0.0022669      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                             \t|  0.0049244      \t|  1              \t|  0.0049244      \t|  0.0022437      \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                  \t|  0.0046145      \t|  1              \t|  0.0046145      \t|  0.0021025      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_after_backward                                                                                      \t|  3.7134e-06     \t|  930            \t|  0.0034535      \t|  0.0015735      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.configure_optimizers                                                                                                           \t|  0.0024741      \t|  1              \t|  0.0024741      \t|  0.0011273      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_end                                                                                     \t|  2.3365e-06     \t|  930            \t|  0.002173       \t|  0.00099006     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_zero_grad                                                                                    \t|  2.2652e-06     \t|  930            \t|  0.0021067      \t|  0.00095985     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_batch_start                                                                                   \t|  2.1111e-06     \t|  930            \t|  0.0019633      \t|  0.00089452     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_optimizer_step                                                                               \t|  2.0803e-06     \t|  930            \t|  0.0019347      \t|  0.00088151     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                          \t|  1.9546e-06     \t|  930            \t|  0.0018178      \t|  0.00082822     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_before_backward                                                                                     \t|  1.721e-06      \t|  930            \t|  0.0016006      \t|  0.00072926     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_before_batch_transfer                                                                                                       \t|  1.5025e-06     \t|  982            \t|  0.0014754      \t|  0.00067224     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                      \t|  1.4508e-06     \t|  930            \t|  0.0013492      \t|  0.00061473     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_after_backward                                                                                                              \t|  1.3774e-06     \t|  930            \t|  0.001281       \t|  0.00058365     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                             \t|  1.3317e-06     \t|  930            \t|  0.0012385      \t|  0.0005643      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  1.318e-06      \t|  930            \t|  0.0012258      \t|  0.00055849     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                   \t|  1.3127e-06     \t|  930            \t|  0.0012208      \t|  0.00055621     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  1.2768e-06     \t|  930            \t|  0.0011874      \t|  0.00054103     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_train_batch_end                                                                                                             \t|  1.2389e-06     \t|  930            \t|  0.0011522      \t|  0.00052497     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                      \t|  0.0011439      \t|  1              \t|  0.0011439      \t|  0.0005212      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                       \t|  1.1741e-06     \t|  930            \t|  0.0010919      \t|  0.0004975      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_before_zero_grad                                                                                                            \t|  1.1719e-06     \t|  930            \t|  0.0010899      \t|  0.00049657     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_train_batch_start                                                                                                           \t|  1.1353e-06     \t|  930            \t|  0.0010558      \t|  0.00048105     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                        \t|  1.0552e-06     \t|  930            \t|  0.00098134     \t|  0.00044712     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                  \t|  1.0446e-06     \t|  930            \t|  0.00097145     \t|  0.00044262     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_after_batch_transfer                                                                                                        \t|  9.6871e-07     \t|  982            \t|  0.00095127     \t|  0.00043342     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                          \t|  1.0163e-06     \t|  930            \t|  0.0009452      \t|  0.00043065     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  1.0103e-06     \t|  930            \t|  0.00093955     \t|  0.00042808     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_before_optimizer_step                                                                                                       \t|  9.9078e-07     \t|  930            \t|  0.00092143     \t|  0.00041982     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                         \t|  9.839e-07      \t|  930            \t|  0.00091503     \t|  0.00041691     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  9.7923e-07     \t|  930            \t|  0.00091068     \t|  0.00041493     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  9.5325e-07     \t|  930            \t|  0.00088653     \t|  0.00040392     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                           \t|  9.1117e-07     \t|  930            \t|  0.00084739     \t|  0.00038609     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                            \t|  8.9456e-07     \t|  930            \t|  0.00083194     \t|  0.00037905     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_before_backward                                                                                                             \t|  8.278e-07      \t|  930            \t|  0.00076986     \t|  0.00035077     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.00055083     \t|  1              \t|  0.00055083     \t|  0.00025097     \t|\n",
      "|  [LightningDataModule]SocialBiasDataModule.val_dataloader                                                                                                             \t|  0.00042688     \t|  1              \t|  0.00042688     \t|  0.0001945      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  5.7958e-05     \t|  6              \t|  0.00034775     \t|  0.00015844     \t|\n",
      "|  [LightningDataModule]SocialBiasDataModule.train_dataloader                                                                                                           \t|  0.00026217     \t|  1              \t|  0.00026217     \t|  0.00011945     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                       \t|  2.5265e-06     \t|  52             \t|  0.00013138     \t|  5.9859e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_end                                                                                \t|  2.199e-06      \t|  52             \t|  0.00011435     \t|  5.21e-05       \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_batch_start                                                                              \t|  2.109e-06      \t|  52             \t|  0.00010967     \t|  4.9966e-05     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_batch_start                                                                                                      \t|  1.8409e-06     \t|  52             \t|  9.5729e-05     \t|  4.3616e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                     \t|  1.6073e-06     \t|  52             \t|  8.3578e-05     \t|  3.808e-05      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_start                                                                                    \t|  1.1971e-05     \t|  6              \t|  7.1826e-05     \t|  3.2726e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  1.3374e-06     \t|  52             \t|  6.9543e-05     \t|  3.1685e-05     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_batch_end                                                                                                        \t|  1.2479e-06     \t|  52             \t|  6.4893e-05     \t|  2.9567e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  1.172e-06      \t|  52             \t|  6.0945e-05     \t|  2.7768e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_start                                                                                         \t|  3.2531e-05     \t|  1              \t|  3.2531e-05     \t|  1.4822e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                          \t|  5.5544e-06     \t|  5              \t|  2.7772e-05     \t|  1.2654e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                            \t|  5.5402e-06     \t|  5              \t|  2.7701e-05     \t|  1.2621e-05     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_epoch_start                                                                                                      \t|  4.377e-06      \t|  6              \t|  2.6262e-05     \t|  1.1966e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                   \t|  4.335e-06      \t|  6              \t|  2.601e-05      \t|  1.1851e-05     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_epoch_end                                                                                                        \t|  3.9942e-06     \t|  6              \t|  2.3965e-05     \t|  1.0919e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_epoch_start                                                                                   \t|  4.775e-06      \t|  5              \t|  2.3875e-05     \t|  1.0878e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                           \t|  3.4532e-06     \t|  6              \t|  2.0719e-05     \t|  9.4401e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_start                                                                              \t|  3.1845e-06     \t|  6              \t|  1.9107e-05     \t|  8.7056e-06     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                             \t|  2.8255e-06     \t|  6              \t|  1.6953e-05     \t|  7.7242e-06     \t|\n",
      "|  [LightningDataModule]SocialBiasDataModule.setup                                                                                                                      \t|  1.6631e-05     \t|  1              \t|  1.6631e-05     \t|  7.5775e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_epoch_end                                                                                \t|  2.3727e-06     \t|  6              \t|  1.4236e-05     \t|  6.4863e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_validation_end                                                                                      \t|  2.251e-06      \t|  6              \t|  1.3506e-05     \t|  6.1537e-06     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_train_epoch_start                                                                                                           \t|  2.2704e-06     \t|  5              \t|  1.1352e-05     \t|  5.1722e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  1.8853e-06     \t|  6              \t|  1.1312e-05     \t|  5.154e-06      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_train_start                                                                                                                 \t|  1.047e-05      \t|  1              \t|  1.047e-05      \t|  4.7704e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                      \t|  9.068e-06      \t|  1              \t|  9.068e-06      \t|  4.1316e-06     \t|\n",
      "|  [LightningDataModule]SocialBiasDataModule.state_dict                                                                                                                 \t|  4.4385e-06     \t|  2              \t|  8.877e-06      \t|  4.0446e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                  \t|  1.3762e-06     \t|  6              \t|  8.257e-06      \t|  3.7621e-06     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_start                                                                                                            \t|  1.2608e-06     \t|  6              \t|  7.565e-06      \t|  3.4468e-06     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                       \t|  1.2337e-06     \t|  6              \t|  7.402e-06      \t|  3.3725e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  7.254e-06      \t|  1              \t|  7.254e-06      \t|  3.3051e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                  \t|  7.244e-06      \t|  1              \t|  7.244e-06      \t|  3.3005e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                    \t|  1.2005e-06     \t|  6              \t|  7.203e-06      \t|  3.2819e-06     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                     \t|  1.1823e-06     \t|  6              \t|  7.094e-06      \t|  3.2322e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                        \t|  7.054e-06      \t|  1              \t|  7.054e-06      \t|  3.214e-06      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_validation_end                                                                                                              \t|  1.162e-06      \t|  6              \t|  6.972e-06      \t|  3.1766e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  1.1205e-06     \t|  6              \t|  6.723e-06      \t|  3.0632e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  1.0585e-06     \t|  6              \t|  6.351e-06      \t|  2.8937e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  1.2462e-06     \t|  5              \t|  6.231e-06      \t|  2.839e-06      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                     \t|  1.0348e-06     \t|  6              \t|  6.209e-06      \t|  2.829e-06      \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                \t|  5.781e-06      \t|  1              \t|  5.781e-06      \t|  2.634e-06      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_save_checkpoint                                                                                     \t|  2.6555e-06     \t|  2              \t|  5.311e-06      \t|  2.4198e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.setup                                                                                                  \t|  4.769e-06      \t|  1              \t|  4.769e-06      \t|  2.1729e-06     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.configure_callbacks                                                                                                            \t|  4.729e-06      \t|  1              \t|  4.729e-06      \t|  2.1546e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_train_end                                                                                           \t|  3.917e-06      \t|  1              \t|  3.917e-06      \t|  1.7847e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_end                                                                                             \t|  3.857e-06      \t|  1              \t|  3.857e-06      \t|  1.7573e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_start                                                                                  \t|  3.346e-06      \t|  1              \t|  3.346e-06      \t|  1.5245e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                        \t|  3.166e-06      \t|  1              \t|  3.166e-06      \t|  1.4425e-06     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                         \t|  2.726e-06      \t|  1              \t|  2.726e-06      \t|  1.242e-06      \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                            \t|  1.227e-06      \t|  2              \t|  2.454e-06      \t|  1.1181e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_fit_start                                                                                           \t|  2.254e-06      \t|  1              \t|  2.254e-06      \t|  1.027e-06      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.teardown                                                                                               \t|  2.165e-06      \t|  1              \t|  2.165e-06      \t|  9.8643e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                         \t|  1.032e-06      \t|  2              \t|  2.064e-06      \t|  9.4041e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  1.963e-06      \t|  1              \t|  1.963e-06      \t|  8.9439e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                         \t|  1.954e-06      \t|  1              \t|  1.954e-06      \t|  8.9029e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  9.57e-07       \t|  2              \t|  1.914e-06      \t|  8.7206e-07     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val_loss', 'mode': 'min'}.on_sanity_check_end                                                                                    \t|  1.904e-06      \t|  1              \t|  1.904e-06      \t|  8.6751e-07     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_fit_start                                                                                                                   \t|  1.863e-06      \t|  1              \t|  1.863e-06      \t|  8.4883e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                 \t|  1.713e-06      \t|  1              \t|  1.713e-06      \t|  7.8048e-07     \t|\n",
      "|  [LightningDataModule]SocialBiasDataModule.teardown                                                                                                                   \t|  1.603e-06      \t|  1              \t|  1.603e-06      \t|  7.3037e-07     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                    \t|  1.583e-06      \t|  1              \t|  1.583e-06      \t|  7.2125e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                   \t|  1.513e-06      \t|  1              \t|  1.513e-06      \t|  6.8936e-07     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_train_end                                                                                                                   \t|  1.442e-06      \t|  1              \t|  1.442e-06      \t|  6.5701e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  1.433e-06      \t|  1              \t|  1.433e-06      \t|  6.5291e-07     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                      \t|  1.363e-06      \t|  1              \t|  1.363e-06      \t|  6.2102e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  1.363e-06      \t|  1              \t|  1.363e-06      \t|  6.2102e-07     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_save_checkpoint                                                                                                             \t|  6.715e-07      \t|  2              \t|  1.343e-06      \t|  6.119e-07      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.on_fit_end                                                                                                                     \t|  1.343e-06      \t|  1              \t|  1.343e-06      \t|  6.119e-07      \t|\n",
      "|  [LightningModule]SocialBiasClassifier.setup                                                                                                                          \t|  1.323e-06      \t|  1              \t|  1.323e-06      \t|  6.0279e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                               \t|  1.153e-06      \t|  1              \t|  1.153e-06      \t|  5.2533e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  1.082e-06      \t|  1              \t|  1.082e-06      \t|  4.9299e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  1.032e-06      \t|  1              \t|  1.032e-06      \t|  4.702e-07      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                          \t|  9.82e-07       \t|  1              \t|  9.82e-07       \t|  4.4742e-07     \t|\n",
      "|  [LightningModule]SocialBiasClassifier.teardown                                                                                                                       \t|  9.52e-07       \t|  1              \t|  9.52e-07       \t|  4.3375e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                           \t|  9.22e-07       \t|  1              \t|  9.22e-07       \t|  4.2009e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  8.52e-07       \t|  1              \t|  8.52e-07       \t|  3.8819e-07     \t|\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
